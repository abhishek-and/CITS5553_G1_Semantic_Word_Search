{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1a0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "def Find_Semantically_Similar_Words(words, similarity_threshold):\n",
    "    \n",
    "    # Get the current directory\n",
    "    current_directory = os.getcwd()\n",
    "    # Directory for extracted contents\n",
    "    extracted_directory = os.path.join(current_directory, 'Extracted_TenderFiles_1')\n",
    "    \n",
    "    dataset = pd.read_excel('Contracts_Dataset.xlsx', dtype=str)\n",
    "    semantically_similar_list = {}\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    \n",
    "    for word in words:        \n",
    "        similar_words_by_reference_number = {}\n",
    "        \n",
    "        # Loop through the DataFrame one row at a time\n",
    "        for index, row in dataset.iterrows():\n",
    "            reference_number = row['Reference Number']\n",
    "            \n",
    "            # Get Contract Title, Description, UNSPSC Title, Supplier Name\n",
    "            one_row_doc = row['Contract Title'] + ' ' + row['Description'] + ' ' + row['UNSPSC Title'] + ' ' + row['Supplier Name']\n",
    "            \n",
    "            document = nlp(one_row_doc)\n",
    "            \n",
    "            similar_words = set()\n",
    "            for token in document:\n",
    "                # Calculate the similarity score between the target word and each token in the document\n",
    "                similarity_score = token.similarity(nlp(word))\n",
    "\n",
    "\n",
    "                if similarity_score > similarity_threshold:\n",
    "                    similar_words.add(token.text)\n",
    "            \n",
    "            similar_words_by_reference_number[reference_number] = similar_words\n",
    "    \n",
    "    semantically_similar_list[word] = similar_words_by_reference_number\n",
    "        \n",
    "    return semantically_similar_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44103a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aanand\\AppData\\Local\\Temp\\ipykernel_4420\\1129935439.py:36: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity_score = token.similarity(nlp(word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CCTV': {'ARA201901891': set(), '20221AGWA': set(), 'FIN873DLGSCAG': set(), '2020153WAM': set(), 'CUAHRS202117042023AC': set(), 'RFQ13042023ACT': set(), 'E03052023ACT': set(), 'RFQ06122022ACT2': set(), 'CUAAFA201807032023AC': set(), 'CUAPCS201829112022AC': set(), 'WR05042022ACT': set(), 'E19012023ACT': set(), 'E10022023ACT': set(), 'E14122022ACT': set(), 'E29112022ACT': set(), 'RFQ08042022ACT': set(), 'E11102022ACT': set(), 'RFQ06042022PTT': set(), 'RFQ06072022ACT': set(), 'E12072022ACT': set(), 'E05072022ACT': set(), 'RFQ05042022PTT': set(), 'CUATPS201907072022AC': set(), 'E10042022PTT': set(), 'CUATPS201914062022PT': set(), 'CUATPS201908042022PT': set(), '07012022PTT': set(), '02022021DLGSCPTT': set(), '04022022CUATP2019': set(), '18122020DLGSCPTT': set(), '02122020DLGSCPTT': set(), '204340DLGSC': set(), 'PTT05062019': set(), '3092020DLGSCPTT': set(), 'E20402DLGSCPTT': set(), 'E20400DLGSCPTT': set(), 'E2019192449DLGSCPTT': set(), 'E2019CA1958DLGSCPTT': set(), 'INF4CA20199': set(), 'DBCABGPA20202023': set(), 'DBCABGPA20052023': set(), 'DBCABGPA20122023': set(), 'DBCABGPA10452022': set(), 'DBCABGPA20022023': set(), 'DBCABGPA10072023': set(), 'DBCABGPA30162023': set(), 'DBCABGPA20032023': set(), 'DBCABGPA30362022': set(), 'DBCABGPA20512022': set(), 'DBCABGPA20442022': set(), 'DBCABGPA20462022': set(), 'DBCABGPA20012022': set(), 'DBCABGPA20292022': set(), 'DBCABGPA20242022': set(), 'DBCABGPA20142022': set(), 'DBCABGPA20112022': set(), 'DBCABGPA20172022': set(), 'DBCABGPA20232022': set(), 'DBCABGPA30242021': set(), 'DBCABGPA20272022': set(), 'DBCABGPA20162022': set(), 'DBCABGPA10202022': set(), 'DBCABGPA20192022': set(), 'DBCABGPA20092022': set(), 'DBCABGPA10122022': set(), 'DBCABGPA20222022': set(), 'DBCABGPA20102022': set(), 'DBCABGPA10312021': set(), 'DBCABGPA20152022': set(), 'DBCABGPA20102021': set(), 'DBCABGPA10012021': set(), 'DBCABGPA20332021': set(), 'DBCABGPA20302021': set(), 'DBCABGPA20282021': set(), 'DBCABGPA20222021': set(), 'DBCABGPA10132021': set(), 'DBCABGPA10122021': set()}}\n"
     ]
    }
   ],
   "source": [
    "# You can adjust the threshold as needed to filter out less similar words\n",
    "semantically_similar_list = Find_Semantically_Similar_Words(['CCTV'], 0.8)\n",
    "print(semantically_similar_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
