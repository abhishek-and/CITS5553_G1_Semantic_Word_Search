{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa0e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install PyMuPD4F\n",
    "# pip install python-docx\n",
    "# pip install spacy\n",
    "# python -m spacy download en_core_web_sm - On Terminal\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import traceback\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Read the dataset\n",
    "dataset = pd.read_excel('Contracts_Dataset.xlsx', dtype=str)\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Directory containing the .zip files\n",
    "download_directory = os.path.join(current_directory, 'TenderFiles')\n",
    "\n",
    "# Destination directory for extracted contents\n",
    "extract_directory = os.path.join(current_directory, 'Tender_Files_Extract')\n",
    "\n",
    "# POS Tags of interest\n",
    "pos_tags_of_interest = ['NOUN', 'VERB', 'ADJ', 'ADV']\n",
    "\n",
    "# NER Tags of interest\n",
    "ner_tags_of_interest = ['ORG', 'GPE', 'LOC', 'NORP', 'PRODUCT', 'EVENT', 'SCIENCE', 'ARTICLE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d07dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the destination directory exists\n",
    "if not os.path.exists(extract_directory):\n",
    "    os.makedirs(extract_directory)\n",
    "\n",
    "file_counter = 0\n",
    "# Iterate through the files in the Tenders directory and unzip all of them\n",
    "for file_name in os.listdir(download_directory):\n",
    "    \n",
    "    # Check if the file has a .zip extension\n",
    "    if file_name.endswith('.zip'):\n",
    "        file_counter += 1\n",
    "        file_path = os.path.join(download_directory, file_name)\n",
    "        \n",
    "        if file_counter % 100 == 0:\n",
    "            print('Counter: ' + str(file_counter) + ' ' + file_name)\n",
    "        \n",
    "        tender_reference_number = file_name.split('-')[0]\n",
    "        tender_extract_path = os.path.join(extract_directory, tender_reference_number)\n",
    "        try:\n",
    "            # Open the ZIP file\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                # Extract all contents to the destination directory\n",
    "                zip_ref.extractall(tender_extract_path)\n",
    "\n",
    "        except zipfile.BadZipFile as e:\n",
    "            print(f\"Error 1: {e} - {file_path} is not a valid ZIP file.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred 1: {e}\")\n",
    "        \n",
    "        # File has been unzipped - Look for more zip files within extracted content and unzip them\n",
    "        for inner_file_name in os.listdir(tender_extract_path):\n",
    "            \n",
    "            # Check if the file has a .zip extension\n",
    "            if inner_file_name.endswith('.zip'):\n",
    "                inner_file_path = os.path.join(tender_extract_path, inner_file_name)\n",
    "                try:\n",
    "                    with zipfile.ZipFile(inner_file_path, 'r') as zip_ref_inner:\n",
    "                        zip_ref_inner.extractall(tender_extract_path)\n",
    "                except zipfile.BadZipFile as e:\n",
    "                    continue\n",
    "                    #print(f\"Error 2: {e} - {inner_file_path} is not a valid ZIP file.\")\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                    #print(f\"An error occurred 2: {inner_file_name} -- {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8049b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import fitz\n",
    "import docx\n",
    "\n",
    "# Extract the textual content from all pdf and docx files\n",
    "tenders = [f for f in os.listdir(extract_directory) if os.path.isdir(os.path.join(extract_directory, f))]\n",
    "file_counter = 0\n",
    "\n",
    "# Now, subfolders contains a list of subfolder names in the specified folder\n",
    "for tender_reference_number in tenders:\n",
    "    tender_file_path = os.path.join(extract_directory, tender_reference_number)\n",
    "    tender_summary_file_path = os.path.join(extract_directory, tender_reference_number + \".txt\")\n",
    "    \n",
    "    file_counter += 1\n",
    "    if file_counter % 100 == 0:\n",
    "        print('Counter: ' + str(file_counter) + ' ' + file_name)\n",
    "\n",
    "    # Create an empty summary file first\n",
    "    text_content = ''\n",
    "    with open(tender_summary_file_path, 'w') as file:\n",
    "        file.write(text_content)\n",
    "    \n",
    "    try:\n",
    "        for root, dirs, files in os.walk(tender_file_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                if file.endswith('.pdf'):\n",
    "                    try:\n",
    "                        pdf_document = fitz.open(file_path)\n",
    "\n",
    "                        # Iterate through each page in the PDF\n",
    "                        for page_num in range(pdf_document.page_count):\n",
    "                            page = pdf_document[page_num]\n",
    "                            text_content += page.get_text()\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                    finally:\n",
    "                        # Close the PDF document\n",
    "                        pdf_document.close()\n",
    "\n",
    "                if file.endswith('.docx'):\n",
    "                    try:\n",
    "                        doc = docx.Document(file_path)\n",
    "                        for paragraph in doc.paragraphs:\n",
    "                            text_content += paragraph.text + '\\n'\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    finally:\n",
    "        with open(tender_summary_file_path, 'a', encoding='utf-8') as file_writer:\n",
    "            file_writer.write(text_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c460b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "row_counter = 0\n",
    "\n",
    "# Filter the list to get only .txt files\n",
    "files = [file for file in os.listdir(extract_directory) if file.endswith(\".txt\")]\n",
    "for file in files:\n",
    "    row_counter += 1\n",
    "    if row_counter % 10 == 0:\n",
    "        print(row_counter)\n",
    "    \n",
    "    file_path = os.path.join(extract_directory, file)\n",
    "    file_name_without_extension = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    tender_useful_summary_file_path = os.path.join(extract_directory, file_name_without_extension + \"_useful.sum\")\n",
    "    # Create an empty summary file first\n",
    "    with open(tender_useful_summary_file_path, 'w') as file:\n",
    "        file.write('')\n",
    "\n",
    "    tender_useful_content = ''\n",
    "    with open(file_path, 'r', encoding='utf-8') as tender_file:\n",
    "        useful_tokens = []\n",
    "        tender_contents = tender_file.read()\n",
    "        if len(tender_contents) > 1000000:\n",
    "            tender_contents = tender_contents[:1000000]\n",
    "\n",
    "        # Process the document with spaCy\n",
    "        tender_doc = nlp(tender_contents)\n",
    "        \n",
    "        for token in tender_doc:\n",
    "            if token.pos_ in pos_tags_of_interest and token.text not in useful_tokens:\n",
    "                useful_tokens.append(token.text)\n",
    "        \n",
    "        for ent in tender_doc.ents:\n",
    "            if ent.label_ in ner_tags_of_interest and ent.text not in useful_tokens:\n",
    "                useful_tokens.append(token.text)\n",
    "\n",
    "        tender_useful_content = \" \".join(useful_tokens).strip()\n",
    "\n",
    "        with open(tender_useful_summary_file_path, 'a', encoding='utf-8') as file_writer:\n",
    "            file_writer.write(tender_useful_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ee6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "26475\n"
     ]
    }
   ],
   "source": [
    "trimmed_data = {'Reference Number': [], 'Client Agency': [], 'Type of Work': [],\n",
    "                'Contract Title': [], 'Description': [], \n",
    "                'Tender Closing Date': [],\n",
    "                'UNSPSC Code': [], 'UNSPSC Title': [],\n",
    "                'Procurement Method': [],\n",
    "                'Revised Contract Value': [],\n",
    "                'Supplier Name': [], 'Tenders Content': []}\n",
    "trimmed_df = pd.DataFrame(trimmed_data)\n",
    "trimmed_df.to_csv('Contracts_Dataset_With_Extract.csv', index=False)\n",
    "rows_to_add = []\n",
    "row_counter = 0\n",
    "total_number_of_rows = len(dataset)\n",
    "\n",
    "# Loop through the DataFrame one row at a time\n",
    "for index, row in dataset.iterrows():\n",
    "    row_counter += 1\n",
    "    reference_number = row['Reference Number'].strip()\n",
    "    client_agency = row['Client Agency'].strip()\n",
    "    type_of_work = row['Type of Work'].strip()\n",
    "    title = row['Contract Title'].strip()\n",
    "    \n",
    "    description = row['Description'].strip()\n",
    "    soup = BeautifulSoup(description, 'lxml')\n",
    "    description_text = ''.join(soup.stripped_strings)\n",
    "    \n",
    "    tender_closing_date = row['Tender Closing Date'].strip()\n",
    "    unspsc_code = row['UNSPSC Code'].strip()\n",
    "    unspsc_title = row['UNSPSC Title'].strip()\n",
    "    proceurement_method = str(row['Procurement Method']).strip()\n",
    "    revised_contract_value = row['Revised Contract Value'].strip()\n",
    "    supplier_name = str(row['Supplier Name']).strip()\n",
    "\n",
    "    \n",
    "    # Check if extracted tender file exists for the reference number\n",
    "    tender_useful_content = ''\n",
    "    file_path = os.path.join(extract_directory, reference_number + \"_useful.sum\")\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as tender_file:\n",
    "            useful_tokens = []\n",
    "            tender_contents = tender_file.read()\n",
    "            tender_useful_content = re.sub(r'[^a-zA-Z0-9\\s]', '', tender_contents)\n",
    "        \n",
    "    \n",
    "    new_row = {\n",
    "        'Reference Number': reference_number,\n",
    "        'Client Agency': client_agency,\n",
    "        'Type of Work': type_of_work,\n",
    "        'Contract Title': title,\n",
    "        'Description': description_text,\n",
    "        'Tender Closing Date': tender_closing_date,\n",
    "        'UNSPSC Code': unspsc_code,\n",
    "        'UNSPSC Title': unspsc_title,\n",
    "        'Procurement Method': proceurement_method,\n",
    "        'Revised Contract Value': revised_contract_value,\n",
    "        'Supplier Name': supplier_name,\n",
    "        'Tenders Content': tender_useful_content\n",
    "    }\n",
    "    rows_to_add.append(new_row)\n",
    "    \n",
    "    \n",
    "    if row_counter % 1000 == 0 or row_counter == total_number_of_rows:\n",
    "        print(row_counter)\n",
    "        trimmed_df = pd.DataFrame(trimmed_data)\n",
    "        trimmed_df = pd.concat([trimmed_df, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
    "        trimmed_df.to_csv('Contracts_Dataset_With_Extract.csv', mode='a', header=False, index=False)\n",
    "        rows_to_add = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c521eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
