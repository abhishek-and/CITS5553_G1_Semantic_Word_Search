{"cells":[{"cell_type":"code","execution_count":null,"id":"0aa0e550","metadata":{"id":"0aa0e550"},"outputs":[],"source":["# pip install PyMuPDF\n","# pip install python-docx\n","# pip install spacy\n","# python -m spacy download en_core_web_sm - On Terminal\n","\n","import os\n","import zipfile\n","import pandas as pd\n","import numpy as np\n","import warnings\n","from collections import defaultdict\n","import traceback\n","from bs4 import BeautifulSoup\n","\n","# Read the dataset\n","dataset = pd.read_excel('Contracts_Dataset.xlsx', dtype=str)\n","\n","# Get the current directory\n","current_directory = os.getcwd()\n","\n","# Directory containing the .zip files\n","download_directory = os.path.join(current_directory, 'Tender_Files_1')\n","\n","# Destination directory for extracted contents\n","extract_directory = os.path.join(current_directory, 'Tender_Files_Extract_1')\n","\n","# POS Tags of interest\n","pos_tags_of_interest = ['NOUN', 'VERB', 'ADJ', 'ADV']\n","\n","# NER Tags of interest\n","ner_tags_of_interest = ['ORG', 'GPE', 'LOC', 'NORP', 'PRODUCT', 'EVENT', 'SCIENCE', 'ARTICLE']\n"]},{"cell_type":"code","execution_count":null,"id":"21d07dc9","metadata":{"id":"21d07dc9"},"outputs":[],"source":["# Ensure the destination directory exists\n","if not os.path.exists(extract_directory):\n","    os.makedirs(extract_directory)\n","\n","# Iterate through the files in the Tenders directory and unzip all of them\n","for file_name in os.listdir(download_directory):\n","    file_path = os.path.join(download_directory, file_name)\n","\n","    # Check if the file has a .zip extension\n","    if file_name.endswith('.zip'):\n","        tender_reference_number = file_name.split('-')[0]\n","        tender_extract_path = os.path.join(extract_directory, tender_reference_number)\n","        try:\n","            # Open the ZIP file\n","            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n","                # Extract all contents to the destination directory\n","                zip_ref.extractall(tender_extract_path)\n","\n","        except zipfile.BadZipFile as e:\n","            print(f\"Error: {e} - {file_path} is not a valid ZIP file.\")\n","        except Exception as e:\n","            print(f\"An error occurred: {e}\")\n","\n","        # File has been unzipped - Look for more zip files within extracted content and unzip them\n","        for inner_file_name in os.listdir(tender_extract_path):\n","            inner_file_path = os.path.join(tender_extract_path, inner_file_name)\n","\n","            # Check if the file has a .zip extension\n","            if inner_file_name.endswith('.zip'):\n","                try:\n","                    with zipfile.ZipFile(inner_file_path, 'r') as zip_ref:\n","                        zip_ref.extractall(tender_extract_path)\n","                except zipfile.BadZipFile as e:\n","                    print(f\"Error: {e} - {inner_file_path} is not a valid ZIP file.\")\n","                except Exception as e:\n","                    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"id":"c8049b06","metadata":{"id":"c8049b06"},"outputs":[],"source":["import glob\n","import fitz\n","import docx\n","\n","# Extract the textual content from all pdf and docx files\n","tenders = [f for f in os.listdir(extract_directory) if os.path.isdir(os.path.join(extract_directory, f))]\n","\n","# Now, subfolders contains a list of subfolder names in the specified folder\n","for tender_reference_number in tenders:\n","    tender_file_path = os.path.join(extract_directory, tender_reference_number)\n","    tender_summary_file_path = os.path.join(extract_directory, tender_reference_number + \".txt\")\n","\n","    # Create an empty summary file first\n","    with open(tender_summary_file_path, 'w') as file:\n","        file.write('')\n","\n","    for root, dirs, files in os.walk(tender_file_path):\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            text_content = ''\n","\n","            if file.endswith('.pdf'):\n","                pdf_document = fitz.open(file_path)\n","\n","                # Iterate through each page in the PDF\n","                for page_num in range(pdf_document.page_count):\n","                    page = pdf_document[page_num]\n","                    text_content += page.get_text()\n","\n","                # Close the PDF document\n","                pdf_document.close()\n","\n","            if file.endswith('.docx'):\n","                doc = docx.Document(file_path)\n","                for paragraph in doc.paragraphs:\n","                    text_content += paragraph.text + '\\n'\n","\n","            with open(tender_summary_file_path, 'a', encoding='utf-8') as file_writer:\n","                file_writer.write(text_content)\n"]},{"cell_type":"code","execution_count":null,"id":"3cacce8a","metadata":{"id":"3cacce8a","outputId":"8437ef7a-e261-43f7-a51b-695c1db342af"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\rashi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\rashi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: yake in d:\\anaconda\\lib\\site-packages (0.4.8)\n","Requirement already satisfied: jellyfish in d:\\anaconda\\lib\\site-packages (from yake) (1.0.0)\n","Requirement already satisfied: tabulate in d:\\anaconda\\lib\\site-packages (from yake) (0.9.0)\n","Requirement already satisfied: networkx in c:\\users\\rashi\\appdata\\roaming\\python\\python39\\site-packages (from yake) (3.1)\n","Requirement already satisfied: click>=6.0 in d:\\anaconda\\lib\\site-packages (from yake) (8.0.3)\n","Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from yake) (1.22.4)\n","Requirement already satisfied: segtok in d:\\anaconda\\lib\\site-packages (from yake) (1.5.11)\n","Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click>=6.0->yake) (0.4.6)\n","Requirement already satisfied: regex in d:\\anaconda\\lib\\site-packages (from segtok->yake) (2021.8.3)\n"]}],"source":["import nltk\n","import os\n","import pandas as pd\n","import yake\n","from bs4 import BeautifulSoup\n","# Download necessary NLTK data (you may have already done this)\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","!pip install yake"]},{"cell_type":"code","execution_count":null,"id":"0c02da17","metadata":{"id":"0c02da17"},"outputs":[],"source":["# Initialize YAKE\n","custom_kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, dedupLim=0.9, dedupFunc='seqm')\n","\n","trimmed_data = {'Reference Number': [], 'Contract Title': [], 'Description': [], 'UNSPSC Title': [], 'Supplier Name': [], 'Tenders Content': []}\n","trimmed_df = pd.DataFrame(trimmed_data)\n","rows_to_add = []\n","\n","# Loop through the DataFrame one row at a time\n","for index, row in dataset.iterrows():\n","    reference_number = row['Reference Number'].strip()\n","    title = row['Contract Title'].strip()\n","    description = row['Description'].strip()\n","    soup = BeautifulSoup(description, 'lxml')\n","    description_text = ''.join(soup.stripped_strings)\n","    unspsc_title = row['UNSPSC Title'].strip()\n","    supplier_name = str(row['Supplier Name']).strip()\n","\n","    # Check if the extracted tender file exists for the reference number\n","    tender_useful_content = ''\n","    file_path = os.path.join(extract_directory, reference_number + \".txt\")\n","    if os.path.exists(file_path):\n","        with open(file_path, 'r', encoding='utf-8') as tender_file:\n","            tender_contents = tender_file.read()\n","\n","            # Extract keywords using YAKE\n","            keywords = custom_kw_extractor.extract_keywords(tender_contents)\n","\n","            useful_tokens = [keyword for keyword, score in keywords]\n","\n","            tender_useful_content = \" \".join(useful_tokens).strip()\n","\n","    new_row = {\n","        'Reference Number': reference_number,\n","        'Contract Title': title,\n","        'Description': description_text,\n","        'UNSPSC Title': unspsc_title,\n","        'Supplier Name': supplier_name,\n","        'Tenders Content': tender_useful_content\n","    }\n","    rows_to_add.append(new_row)\n","    x = str(new_row)\n","\n","with open(tender_summary_file_path, 'a', encoding='utf-8') as file_writer:\n","    file_writer.write(x)"]},{"cell_type":"code","execution_count":null,"id":"5c84f9ed","metadata":{"id":"5c84f9ed"},"outputs":[],"source":["import pandas as pd\n","\n","# Load the CSV file\n","#trimmed_df = pd.read_csv('trimmed_dataset_yake.csv')\n","\n","# Display the first few rows\n","#print(trimmed_df['Tenders Content'].head())"]},{"cell_type":"code","execution_count":null,"id":"bd847f53","metadata":{"id":"bd847f53"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}